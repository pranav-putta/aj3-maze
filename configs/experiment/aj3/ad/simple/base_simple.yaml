# @package _global_

defaults:
  - /experiment/aj3/base
  - /trainer: base_ad_trainer
    # teacher
  - /agent@trainer.teacher_agent: base_ppo_agent
  - /net@trainer.teacher_agent.policy: impala_gru
  - /net@trainer.teacher_agent.critic: base_linear_head
    # student
  - /agent@trainer.agent: base_bc_agent
  - /net@trainer.agent.policy: simple_transformer
  - _self_

seed: 1

trainer:
  epochs: 1000
  num_environments: 16
  num_rollout_steps: 50
  eval_frequency: 50

  env:
    difficulty: null
    static_env: True
    static_episode: True
    max_steps: 50
    reward_type: 'distance_to_goal'
    visible_radius: -1
    size: [ 7, 7 ]

  agent:
    optim: 'adamw'
    wd: 0.1
    lr: 1e-3
    policy:
      condition_on: 'sar'
      embd_dim: 64
      hidden_dim: 256

  teacher_agent:
    epsilon: 0.2
    ppo_epochs: 2
    num_minibatches: 2
    val_loss_coef: 0.5
    entropy_coef: 0.01
    max_grad_norm: 0.5
    gamma: 0.99
    tau: 0.95
    use_gae: False
    lr: 1e-3
    optim: 'adamw'
    wd: 0.001


    policy:
      condition_on: 'sa'
      embd_dim: 64
      hidden_dim: 256

      rnn:
        layers: 2

    critic:
      in_features: ${trainer.teacher_agent.policy.hidden_dim}
      out_features: 1

