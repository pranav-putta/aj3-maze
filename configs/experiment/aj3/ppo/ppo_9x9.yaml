# @package _global_

defaults:
  - aj3/ppo/base_ppo

trainer:
  num_rollout_steps: 50
  epochs: 10000
  num_environments: 8

  env:
    size: [ 7, 7 ]
    static_episode: False
#    visible_radius: -1
    difficulty: 'hard'

  agent:
    policy:
      embd_dim: 32
      hidden_dim: 256
      rnn:
        layers: 2
    epsilon: 0.2
    ppo_epochs: 2
    num_minibatches: 2
    value_loss_coef: 0.5
    entropy_coef: 0.01
    max_grad_norm: 0.75
    lr: 1e-4