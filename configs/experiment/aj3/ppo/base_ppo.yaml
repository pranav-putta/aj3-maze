# @package _global_

defaults:
  - /experiment/aj3/base
  - /trainer: base_trainer
  - /agent@trainer.agent: base_ppo_agent
  - /net@trainer.agent.policy: base_impala_net
  - /net@trainer.agent.critic: base_linear_head
  - _self_
 
seed: 10

trainer:
  epochs: 100000
  num_environments: 32
  num_rollout_steps: 50
  eval_frequency: 50

  env:
    difficulty: 'hard'
    static_env: True
    static_episode: True
    max_steps: 50
    reward_type: 'distance_to_goal'
    agent_visibility: -1
  agent:
    policy:
      in_dim: ${trainer.env.size[0]}
      embd_vocab_size: 4
      embd_dim: 64
      hidden_dim: 64
      out_dim: 4
      rnn_layers: 2
      scale: 1
    critic:
      in_features: ${trainer.agent.policy.hidden_dim}
      out_features: 1

    epsilon: 0.2
    ppo_epochs: 4
    num_minibatches: 2
    value_loss_coef: 0.5
    entropy_coef: 0.01
    max_grad_norm: 0.5
    gamma: 0.99
    tau: 0.95
    use_gae: False
    lr: 1e-3