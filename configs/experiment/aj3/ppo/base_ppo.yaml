# @package _global_

defaults:
  - /experiment/aj3/base
  - /trainer: base_trainer
  - /agent@trainer.agent: base_ppo_agent
  - /net@trainer.agent.policy: impala_gru
  - /net@trainer.agent.critic: base_linear_head
  - _self_

seed: 1

trainer:
  epochs: 1000
  num_environments: 16
  num_rollout_steps: 50
  eval_frequency: 50

  env:
    difficulty: null
    static_env: True
    static_episode: True
    max_steps: 50
    reward_type: 'distance_to_goal'
    visible_radius: -1
    size: [ 7, 7 ]

  agent:
    epsilon: 0.2
    ppo_epochs: 2
    num_minibatches: 2
    val_loss_coef: 0.5
    entropy_coef: 0.04
    max_grad_norm: 0.5
    gamma: 0.99
    tau: 0.95
    use_gae: False
    lr: 1e-3
    policy:
      condition_on: 's'
      embd_dim: 32
      hidden_dim: 128
      rnn:
        layers: 2
    critic:
      in_features: ${trainer.agent.policy.hidden_dim}
      out_features: 1
